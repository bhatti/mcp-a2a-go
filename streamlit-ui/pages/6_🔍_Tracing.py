"""
OpenTelemetry Distributed Tracing with Jaeger
End-to-end request visibility across Python and Go services
"""
import streamlit as st
import os

st.set_page_config(page_title="OpenTelemetry Tracing", page_icon="ðŸ”", layout="wide")

st.title("ðŸ” OpenTelemetry Distributed Tracing")

# Get Jaeger URL
jaeger_url = os.getenv('JAEGER_URL', 'http://localhost:16686')

# Overview
st.header("ðŸŽ¯ Overview")

st.info("""
**Full Stack OpenTelemetry Instrumentation:**
- âœ… Go Servers (MCP & A2A): HTTP middleware, tool execution, database queries
- âœ… Python Workflows: LangGraph nodes, MCP calls, LLM invocations
- âœ… Trace Propagation: W3C Trace Context via HTTP headers
- âœ… End-to-End Traces: Streamlit UI â†’ Python â†’ Go â†’ Database â†’ LLM
""")

# Quick Access
col1, col2 = st.columns(2)
with col1:
    st.markdown(f"### ðŸ”— Access Jaeger UI")
    st.markdown(f"**URL**: [{jaeger_url}]({jaeger_url})")
    st.markdown("View distributed traces, search by service, analyze performance")

with col2:
    st.markdown(f"### ðŸ“š Documentation")
    st.markdown("[Testing Guide](../docs/TESTING_OBSERVABILITY.md)")
    st.markdown("[README - Observability](../README.md#-observability)")

# What is Distributed Tracing
st.header("ðŸ“– What is Distributed Tracing?")

st.markdown("""
Distributed tracing tracks requests as they flow through multiple services, helping you:

- ðŸ” **Debug issues**: Find exactly where requests fail or slow down
- âš¡ **Optimize performance**: Identify bottlenecks at code-level granularity
- ðŸ“Š **Understand dependencies**: See how services interact in real-time
- ðŸ› **Root cause analysis**: Trace errors to their origin across service boundaries
- ðŸ’¡ **Capacity planning**: Understand resource utilization patterns
""")

# End-to-End Trace Example
st.header("ðŸŒ End-to-End Trace Example")

st.markdown("""
### RAG Query Flow

Here's what happens when you make a RAG query through the Streamlit UI:

```
[User Query: "machine learning"]
    â†“
[Streamlit UI] user.query (1200ms)
    â†“ HTTP + W3C Trace Context
[Python] rag_workflow.execute (1150ms)
    â”œâ”€ [Python] mcp.hybrid_search (300ms)
    â”‚   â†“ HTTP + traceparent header
    â”‚   â””â”€ [Go MCP] http.request (280ms)
    â”‚       â”œâ”€ [Go MCP] mcp.auth.verify (10ms)
    â”‚       â”œâ”€ [Go MCP] mcp.rate_limit.check (5ms)
    â”‚       â””â”€ [Go MCP] mcp.tool.call (250ms)
    â”‚           â””â”€ [Go MCP] mcp.db.hybrid_search (240ms)
    â”‚               â”œâ”€ [Go MCP] mcp.db.bm25_search (100ms)
    â”‚               â””â”€ [Go MCP] mcp.db.vector_search (120ms)
    â”œâ”€ [Python] llm.generate (800ms)
    â”‚   â””â”€ [Langfuse] Tracks tokens, cost, prompt
    â””â”€ [Python] format.response (50ms)
```

**Key Features:**
- **Single Trace ID**: All spans share the same trace ID across languages
- **Causal Relationships**: Parent-child relationships show call hierarchy
- **Precise Timing**: Understand exactly where time is spent
- **Context Propagation**: User ID, tenant ID flow through all spans
""")

# Trace Anatomy
st.header("ðŸ§¬ Trace Anatomy")

tab1, tab2, tab3 = st.tabs(["Concepts", "Span Attributes", "Example Trace"])

with tab1:
    st.markdown("""
    ### Core Concepts

    **Trace**: Complete end-to-end request journey
    - Has unique `trace_id` (e.g., `0af7651916cd43dd8448eb211c80319c`)
    - Contains multiple spans in a tree structure
    - Spans from different services all share the same trace ID

    **Span**: Individual operation within a trace
    - Has unique `span_id`
    - Has `parent_id` (except root span)
    - Contains timing, status, and attributes

    **Attributes**: Key-value pairs attached to spans
    - Standard: `http.method`, `http.status_code`, `db.system`
    - Custom: `tenant.id`, `user.id`, `tool.name`
    - Help filter and analyze traces

    **W3C Trace Context**: Standard for propagating trace context
    - Header: `traceparent: 00-{trace_id}-{span_id}-{flags}`
    - Automatically propagated by OpenTelemetry
    - Works across languages and frameworks
    """)

with tab2:
    st.markdown("""
    ### Span Attributes

    #### MCP Server Spans
    ```
    http.request
    â”œâ”€ http.method: POST
    â”œâ”€ http.url: /mcp
    â”œâ”€ http.status_code: 200
    â”œâ”€ tenant.id: acme-corp
    â””â”€ user.id: demo-user

    mcp.tool.call
    â”œâ”€ tool.name: hybrid_search
    â”œâ”€ rpc.method: tools/call
    â””â”€ request.id: 1

    mcp.db.hybrid_search
    â”œâ”€ db.system: postgresql
    â”œâ”€ db.operation: hybrid_search
    â”œâ”€ query.type: hybrid
    â”œâ”€ search.type: hybrid
    â”œâ”€ result.count: 5
    â””â”€ limit: 5
    ```

    #### A2A Server Spans
    ```
    a2a.task.execute
    â”œâ”€ task.id: task-123
    â”œâ”€ task.type: search_papers
    â”œâ”€ task.priority: normal
    â””â”€ user.id: demo-user

    a2a.budget.check
    â”œâ”€ budget.tier: pro
    â”œâ”€ budget.remaining: 42.50
    â””â”€ cost.estimated: 0.05
    ```

    #### Python Workflow Spans
    ```
    mcp.hybrid_search
    â”œâ”€ query: machine learning
    â”œâ”€ top_k: 5
    â”œâ”€ user.id: demo-user
    â”œâ”€ tenant.id: acme-corp
    â””â”€ results.count: 5

    llm.generate
    â”œâ”€ llm.model: gpt-4
    â”œâ”€ llm.temperature: 0.7
    â”œâ”€ llm.max_tokens: 2000
    â””â”€ response.length: 487
    ```
    """)

with tab3:
    st.markdown("""
    ### Real Trace Example

    This is what you'll see in Jaeger:

    ```
    Trace: rag-workflow: execute
    Duration: 1200ms
    Services: 2 (rag-workflow, mcp-server)
    Spans: 12

    Timeline:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    0ms      300ms    600ms     900ms     1200ms
    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚rag-workflow: execute                     â”‚ 1200ms
    â”œâ”€â”¤mcp.hybrid_search                â”‚ 300ms
    â”‚ â”œâ”¤http.request                 â”‚ 280ms
    â”‚ â”‚â”œâ”¤mcp.tool.call              â”‚ 250ms
    â”‚ â”‚â”‚â”‚mcp.db.hybrid_search     â”‚ 240ms
    â”‚ â”‚â”‚â”‚â”œâ”¤mcp.db.bm25_search   â”‚ 100ms
    â”‚ â”‚â”‚â”‚â””â”€â”¤mcp.db.vector_searchâ”‚ 120ms
    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¤llm.generate          â”‚ 800ms
    â”‚          â””â”¤format.response       â”‚ 50ms
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ```

    **Insights from this trace:**
    - Total time: 1200ms
    - MCP search: 300ms (25%)
    - LLM generation: 800ms (67%) â† Main bottleneck
    - Database queries: 240ms total
      - Vector search slower than BM25 (120ms vs 100ms)
    - Formatting negligible: 50ms
    """)

# How to Use Jaeger
st.header("ðŸŽ® How to Use Jaeger")

with st.expander("Step-by-Step Guide"):
    st.markdown("""
    ### 1. Access Jaeger UI
    Open [Jaeger UI]({jaeger_url}) in your browser.

    ### 2. Select a Service
    - From the "Service" dropdown, select:
      - `mcp-server` for MCP traces
      - `a2a-server` for A2A traces
      - `rag-workflow` for end-to-end RAG traces

    ### 3. Find Traces
    - Click "Find Traces" to see recent traces
    - Or use filters:
      - **Operation**: Select specific operations (e.g., `mcp.tool.call`)
      - **Tags**: Filter by attributes (e.g., `user.id=demo-user`)
      - **Duration**: Find slow requests (e.g., `>500ms`)

    ### 4. Inspect a Trace
    Click on a trace to see:
    - **Timeline**: Visual representation of spans
    - **Span Details**: Click spans to see attributes
    - **Critical Path**: Highlighted spans on critical path
    - **Service Diagram**: Services involved in the trace

    ### 5. Analyze Performance
    Look for:
    - **Long spans**: Operations taking most time
    - **Error spans**: Spans with error status
    - **Gaps**: Idle time between operations
    - **Parallelization**: Operations that could run in parallel
    """.format(jaeger_url=jaeger_url))

# Common Trace Patterns
st.header("ðŸ” Common Trace Patterns")

col1, col2 = st.columns(2)

with col1:
    st.markdown("""
    ### Successful MCP Request
    ```
    mcp-server: http.request [200ms]
    â”œâ”€ mcp.auth.verify [10ms] âœ…
    â”œâ”€ mcp.rate_limit.check [5ms] âœ…
    â””â”€ mcp.tool.call [185ms] âœ…
        â””â”€ mcp.db.hybrid_search [180ms] âœ…
    ```
    **Status**: All spans green âœ…
    **Total**: 200ms
    """)

    st.markdown("""
    ### Failed Authentication
    ```
    mcp-server: http.request [15ms]
    â”œâ”€ mcp.auth.verify [10ms] âŒ
    â”‚   Error: "Invalid JWT signature"
    â””â”€ [Request rejected]
    ```
    **Status**: Auth span red âŒ
    **Total**: 15ms (fast failure)
    """)

with col2:
    st.markdown("""
    ### Slow Database Query
    ```
    mcp-server: http.request [1200ms]
    â”œâ”€ mcp.auth.verify [10ms] âœ…
    â”œâ”€ mcp.rate_limit.check [5ms] âœ…
    â””â”€ mcp.tool.call [1185ms] âš ï¸
        â””â”€ mcp.db.hybrid_search [1180ms] âš ï¸
            â””â”€ mcp.db.vector_search [1150ms] âš ï¸
    ```
    **Issue**: Vector search taking 1150ms
    **Action**: Check database indexes
    """)

    st.markdown("""
    ### Rate Limited Request
    ```
    mcp-server: http.request [8ms]
    â”œâ”€ mcp.auth.verify [5ms] âœ…
    â””â”€ mcp.rate_limit.check [3ms] âŒ
        Error: "Rate limit exceeded: 100/min"
    ```
    **Status**: Rate limit span red âŒ
    **Response**: HTTP 429
    """)

# Testing Tips
st.header("ðŸ§ª Testing & Debugging Tips")

col1, col2 = st.columns(2)

with col1:
    st.markdown("""
    ### Generate Test Traces

    1. **Make RAG Queries**
       - Go to "MCP RAG" page
       - Enter queries to generate traces
       - Check Jaeger for `rag-workflow` traces

    2. **Create A2A Tasks**
       - Go to "A2A Tasks" page
       - Create tasks to see task lifecycle traces
       - Check Jaeger for `a2a-server` traces

    3. **Use CLI**
       ```bash
       # Make a direct MCP call
       curl -X POST http://localhost:8080/mcp \\
         -H "Content-Type: application/json" \\
         -d '{
           "jsonrpc": "2.0",
           "id": 1,
           "method": "tools/list"
         }'
       ```

    4. **Inject Custom Trace ID**
       ```bash
       # Specify trace ID in header
       curl -X POST http://localhost:8080/mcp \\
         -H "traceparent: 00-trace123-span123-01" \\
         -d '{"jsonrpc":"2.0","id":1,"method":"tools/list"}'
       ```
    """)

with col2:
    st.markdown("""
    ### Debugging Workflows

    1. **Find Slow Requests**
       - In Jaeger, filter by duration: `>500ms`
       - Identify bottleneck spans
       - Optimize slow operations

    2. **Trace Errors**
       - Filter by tags: `error=true`
       - Find error spans (marked red)
       - Check error messages in span logs

    3. **Compare Traces**
       - Select multiple traces
       - Compare timeline and durations
       - Identify performance variations

    4. **Service Dependencies**
       - Use "System Architecture" tab
       - See service call graph
       - Understand dependencies
    """)

# Available Services
st.header("ðŸ“Š Available Services")

services_data = {
    "Service": ["rag-workflow", "mcp-server", "a2a-server"],
    "Language": ["Python", "Go", "Go"],
    "Operations": [
        "execute, mcp.hybrid_search, llm.generate, format.response",
        "http.request, mcp.tool.call, mcp.db.hybrid_search, mcp.auth.verify",
        "a2a.task.execute, a2a.budget.check, a2a.cost.calculate, a2a.sse.publish"
    ],
    "Port": ["N/A", "8080", "8081"]
}

import pandas as pd
st.table(pd.DataFrame(services_data))

# Troubleshooting
st.header("ðŸ”§ Troubleshooting")

with st.expander("No traces appearing in Jaeger"):
    st.markdown("""
    1. **Check if tracing is enabled**:
       ```bash
       docker-compose exec mcp-server env | grep OTEL_ENABLE_TRACING
       # Should show: OTEL_ENABLE_TRACING=true
       ```

    2. **Verify Jaeger is receiving traces**:
       ```bash
       docker-compose logs jaeger | grep -i otlp
       # Should show OTLP receiver logs
       ```

    3. **Check OTLP endpoint configuration**:
       ```bash
       docker-compose exec mcp-server env | grep OTLP
       # Should show: OTEL_EXPORTER_OTLP_ENDPOINT=jaeger:4318
       ```

    4. **Test connectivity**:
       ```bash
       docker-compose exec mcp-server ping -c 1 jaeger
       # Should succeed
       ```
    """)

with st.expander("Traces not propagating between services"):
    st.markdown("""
    1. **Check W3C Trace Context headers**:
       - Python clients should inject `traceparent` header
       - Go services should extract trace context
       - Look for "traceparent" in HTTP requests

    2. **Verify middleware order**:
       - Tracing middleware should be outermost
       - Check: Tracing â†’ Auth â†’ Rate Limit â†’ Handler

    3. **Check Python instrumentation**:
       ```python
       from opentelemetry.propagate import inject
       headers = {}
       inject(headers)  # Should add traceparent header
       ```
    """)

# Best Practices
st.header("ðŸ’¡ Best Practices")

st.markdown("""
### For Development
- âœ… Use 100% sampling to see all traces
- âœ… Add descriptive span names
- âœ… Include relevant attributes (user_id, tenant_id)
- âœ… Log errors in spans

### For Production
- âœ… Use sampling (e.g., 10%) to reduce overhead
- âœ… Always sample on errors
- âœ… Monitor trace storage costs
- âœ… Set up alerts on slow traces
- âœ… Use trace IDs in logs for correlation

### For Debugging
- âœ… Search by trace ID from logs
- âœ… Filter by error status
- âœ… Compare slow vs fast traces
- âœ… Look for patterns in failures
""")

# Next Steps
st.header("ðŸš€ Next Steps")

col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("""
    ### ðŸ“Š Metrics
    - View **Metrics** page for Prometheus data
    - Correlate metrics with traces
    - Set up alerts
    """)

with col2:
    st.markdown("""
    ### ðŸ“ˆ Grafana
    - Create custom dashboards
    - Visualize trace data
    - Set up service graphs
    """)

with col3:
    st.markdown("""
    ### ðŸ“š Learn More
    - [OpenTelemetry Docs](https://opentelemetry.io/docs/)
    - [Jaeger Docs](https://www.jaegertracing.io/docs/)
    - [Testing Guide](../docs/TESTING_OBSERVABILITY.md)
    """)

# Footer
st.divider()
st.caption(f"Jaeger UI: {jaeger_url} | Tracing enabled via OpenTelemetry")
